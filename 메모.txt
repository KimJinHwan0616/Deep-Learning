• 입력 데이터: W×H×D

• 하이퍼파라미터
    필터 개수: K
    필터 크기: F
    스트라이드: S
    패딩: P

• 특성 맵(합성곱층)
    너비: (W1-F+2P)/S+1
    높이: (H1-F+2P)/S+1
    채널: K

• 특성 맵(풀링층)
    너비: (W-F)/S+1
    높이: (H-F)/S+1
    채널: D

입력층(입력 데이터) → 합성곱층(필터+활성화 함수) → 특성 맵
→ 풀링층(필터(가중치X)+활성화 함수) → 특성 맵
→ 완전연결층 → 출력층(+소프트맥스)
##################
- 선형방정식: ｚ = 가중치1 ｘ 특성1 + ... + 가중치m ｘ 특성m + 편향 (m＜n)

- 이미지 데이터(3차원): 높이, 너비, 채널(3: 컬러(RGB), 1: 그레이스케일)

- 필터(filter, 커널): (합성곱＆풀링 층)뉴런
- 특성 맵(feature map): (합성곱＆풀링층)출력 데이터

- 스트라이드(stride): 필터가 데이터에서 이동하는 크기
  ▶ 합성곱: 1
  ▶ 풀링: 풀링 크기 ★

- 패딩(padding): (합성곱 층)입력 데이터 주위에 0을 추가
  ▶ 밸리드 패딩(패딩X): 입력 데이터 크기 ＞ 특성 맵 크기
  ▶ 세임 패딩(패딩O): 입력 데이터 크기 = 특성 맵 크기 ★

- 합성곱층
  ▷ 특성 벡터(Feature Vector) 추출
  ▶ 밸리드＆세임 패딩

- 풀링층(pooling Layer)
  ▷ 이미지 축소(1/2)
  ▷ n차원 벡터 -> 1차원 벡터
  ▶ 최대 풀링: 가장 큰 값 선택 ★
  ▶ 평균 풀링: 평균값 선택

★ 이미지 데이터(너비, 높이, 깊이) → 합성곱층(세임 패딩) → 풀링층 → 밀집층 ★
##################
완전연결층(FC, Fully-Connected lyaer): 이전 층의 모든 노드와 연결된 층
= 밀집층(Dense layer)

배치 연산: 인공 신경망이 다수의 샘플을 동시에 처리하는 것
##################
손실 함수(loss function): 가중치 학습을 위해 출력 함수의 결과와 실제 값 간의 오차를 측정하는 함수
경사 하강법: 학습률(learning rate)과 손실 함수의 순간 기울기를 이용하여 가중치를 업데이트하는 방법
미분의 기울기를 이용하여 오차를 비교하고 최소화하는 방향으로 이동시키는 방법
학습을 통해 얻은 데이터의 추정치가 실제 데이터와 얼마나 차이가 나는지 평가하는 지표
- 평균 제곱 오차(Mean Squared Error, MSE)
- 크로스 엔트로피 오차(Cross Entropy Error, CEE)

특성 추출: 데이터 -> 벡터
